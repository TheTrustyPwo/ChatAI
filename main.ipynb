{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ðŸ¤– EchoAI"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import os\n",
    "from aitextgen import aitextgen\n",
    "from aitextgen.TokenDataset import TokenDataset, merge_datasets\n",
    "from aitextgen.utils import build_gpt2_config\n",
    "from aitextgen.tokenizers import train_tokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Whatsapp Chat Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[parser.py][INFO]: Found 1 txt files in `../data/raw/` folder: ['../data/raw/Starknight.txt']\n",
      "[parser.py][INFO]: Saving ../data/parsed/dataset.txt\n"
     ]
    }
   ],
   "source": [
    "user = 'bad'\n",
    "!cd parser && python parser.py --session_token \"<|endoftext|>\" --user_name $user"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "CUDA is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_23776\\1820905988.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mconfig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuild_gpt2_config\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvocab_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax_length\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_embd\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m512\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_layer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_head\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mai\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0maitextgen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtokenizer_file\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtokenizer_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mto_gpu\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTokenDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtokenizer_file\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtokenizer_file\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mblock_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\aitextgen\\aitextgen.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, model, model_folder, config, vocab_file, merges_file, tokenizer_file, schema_tokens, schema_return, cache_dir, tf_gpt2, to_gpu, to_fp16, verbose, gradient_checkpointing, bos_token, eos_token, unk_token, **kwargs)\u001B[0m\n\u001B[0;32m    272\u001B[0m                 )\n\u001B[0;32m    273\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_fp16\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 274\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_gpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    275\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    276\u001B[0m     def generate(\n",
      "\u001B[1;32mc:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\aitextgen\\aitextgen.py\u001B[0m in \u001B[0;36mto_gpu\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    838\u001B[0m         \u001B[1;34m\"\"\"Moves the model to the specified GPU.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    839\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 840\u001B[1;33m         \u001B[1;32massert\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"CUDA is not installed.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    841\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    842\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"cuda\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: CUDA is not installed."
     ]
    }
   ],
   "source": [
    "dataset = './data/parsed/dataset.txt'\n",
    "train_tokenizer(dataset)\n",
    "tokenizer_file = \"aitextgen.tokenizer.json\"\n",
    "\n",
    "config = build_gpt2_config(vocab_size=5000, max_length=64, dropout=0.0, n_embd=512, n_layer=8, n_head=8)\n",
    "ai = aitextgen(tokenizer_file=tokenizer_file, config=config, to_gpu=True)\n",
    "data = TokenDataset(dataset, tokenizer_file=tokenizer_file, block_size=64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:152: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
      "  f\"Setting `Trainer(checkpoint_callback={checkpoint_callback})` is deprecated in v1.5 and will \"\n",
      "c:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:97: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
      "c:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\callback_connector.py:172: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.\n",
      "  \"Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed\"\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:377: LightningDeprecationWarning: The `Callback.on_batch_end` hook was deprecated in v1.6 and will be removed in v1.8. Please use `Callback.on_train_batch_end` instead.\n",
      "  f\"The `Callback.{hook}` hook was deprecated in v1.6 and\"\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/50000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffad9855c79549cd96bbfd999fffc7f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:2282: LightningDeprecationWarning: `trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7. Use `ProgressBarBase.get_metrics` instead.\n",
      "  \"`trainer.progress_bar_dict` is deprecated in v1.5 and will be removed in v1.7.\"\n",
      "c:\\users\\shuce\\pycharmprojects\\echoai\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:726: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "ai.train(data, batch_size=8, num_steps=50000, generate_every=5000, save_every=5000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ai.generate(1, prompt=\"hello\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}